{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2024 Google LLC. Licensed under the Apache License, Version 2.0 (the \"License\");"
      ],
      "metadata": {
        "id": "rjb9Bm-GZkQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License"
      ],
      "metadata": {
        "id": "WJDBj3YAZuHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "YHgjY5eb7TBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Download a csv file of the embeddings using this [link](https://docs.google.com/forms/d/e/1FAIpQLSeZLIqTCIx1-OiBzUnqXZpu_k5M223ZvMmqwQhMZ_0TkaWhEQ/viewform).\n",
        "\n",
        "The county and ZCTA (zipcode census tabulation area) embeddings are available in different files.\n",
        "\n",
        "Here we assume that you have obtained the embeddings and uploaded them to a Google Drive directory called `pdfm_embeddings/v0/us`."
      ],
      "metadata": {
        "id": "vUOwKv-G7mJ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC7wR5HD5RVR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "#@markdown Specify the path to the embeddings file.\n",
        "embeddings_file_path = '/content/drive/MyDrive/pdfm_embeddings/v0/us/county_embeddings.csv' #@param {type:\"string\"}\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "county_embeddings = pd.read_csv(embeddings_file_path).set_index('place')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_features = [f'feature{x}' for x in range(330)]\n",
        "county_embeddings.head(2)"
      ],
      "metadata": {
        "id": "V_4Lt8Yl5vDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Download and prepare monthly unemployment data at county level from Data Commons"
      ],
      "metadata": {
        "id": "4WTpoJ9sSdhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datacommons_pandas --upgrade --quiet\n",
        "import datacommons_pandas as dc"
      ],
      "metadata": {
        "id": "g0GXwIqZSnaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'UnemploymentRate_Person'\n",
        "# Due to response size limits, we'll query in batches.\n",
        "batch_size = 200\n",
        "\n",
        "all_labels = []\n",
        "for start in range(0, county_embeddings.index.shape[0], batch_size):\n",
        "    batch_indices = county_embeddings.index[start : start + batch_size]\n",
        "    batch_data = dc.build_time_series_dataframe(batch_indices, label)\n",
        "    all_labels.append(batch_data)\n",
        "\n",
        "df_labels = pd.concat(all_labels)\n",
        "\n",
        "print(df_labels.shape)\n",
        "df_labels.head(2)"
      ],
      "metadata": {
        "id": "GPL9O0MBSyc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = df_labels.loc['geoId/01001'].plot(figsize=(5, 3))"
      ],
      "metadata": {
        "id": "Ot3NS6QkaA5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Visualization"
      ],
      "metadata": {
        "id": "AQxbSyO_y3GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the county level geojson file.\n",
        "\n",
        "[link text](https://) The county level geojson file are available in the same folder as the embeddings. Download the geojson file into a local folder or a folder under Google drive. Here we assume that you have downloaded the file in Google Drive folder called pdfm_embeddings/v0/us"
      ],
      "metadata": {
        "id": "grx_A9i2zGDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "#@markdown Specify the path to the county geojson file.\n",
        "county_geojson_file_path = '/content/drive/MyDrive/pdfm_embeddings/v0/us/county.geojson' #@param {type:\"string\"}\n",
        "geo = gpd.read_file(county_geojson_file_path).set_index('place')\n",
        "embeddings = gpd.GeoDataFrame(county_embeddings, geometry=geo.geometry)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "034PL4MmzOq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzE6Lggc0Kn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map out an embedding dimension spatially.\n",
        "\n",
        "In this example, we have mapped out feature0 dimension of the embeddings data for counties in New York."
      ],
      "metadata": {
        "id": "yflH8dcn0hi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_locale(df, index, states=None, counties=None):\n",
        "  df = df[df.index.isin(index)]\n",
        "  if not states and not counties:\n",
        "    return df\n",
        "  filter = df.state.isin(states)\n",
        "  if counties:\n",
        "    filter &= df.county.isin(counties)\n",
        "  return df[filter]\n",
        "\n",
        "feature = embedding_features[0]\n",
        "ax = get_locale(embeddings, county_embeddings.index).plot(feature)\n",
        "_ = ax.set_title(feature + ' in counties')\n",
        "\n",
        "ax = get_locale(embeddings, county_embeddings.index, states=['NY']).plot(feature)\n",
        "_ = ax.set_title(feature + ' in NY counties')"
      ],
      "metadata": {
        "id": "mrAWWAqX0zzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying the embeddings to a Nowcasting usecase.\n",
        "\n",
        "Assume that we have unemployment data from 2024-07 from all counties, and only a subset of counties from 2024-08, we can predict the values for the rest of the counties using the embeddings.\n",
        "\n",
        "We have demonstrated the Nowcasting example using a LightGBM (Light Gradient Boosting Machine) model."
      ],
      "metadata": {
        "id": "KTfn7xDQMBf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"Calculates Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE).\"\"\"\n",
        "    return {\n",
        "        'MAE': metrics.mean_absolute_error(y_true, y_pred),\n",
        "        'MAPE': metrics.mean_absolute_percentage_error(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "def train_and_evaluate(train_data, test_data, feature_sets, test_date, model_params=None):\n",
        "    \"\"\"\n",
        "    Trains and evaluates models on given feature sets.\n",
        "\n",
        "    Args:\n",
        "    - train_data (pd.DataFrame): Training dataset with features and labels.\n",
        "    - test_data (pd.DataFrame): Testing dataset with features and labels.\n",
        "    - feature_sets (dict): Dictionary of feature set names and column lists.\n",
        "    - test_date (str): Target date for prediction in test data.\n",
        "    - model_params (dict, optional): Parameters for the LightGBM model.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with evaluation results for each feature set.\n",
        "    \"\"\"\n",
        "    # Set default model parameters if none are provided\n",
        "    if model_params is None:\n",
        "        model_params = {\n",
        "            'min_child_samples': 10,\n",
        "            'num_leaves': 23,\n",
        "            'max_bin': 100,\n",
        "            'n_estimators': 100,\n",
        "            'learning_rate': 0.1,\n",
        "            'force_col_wise': True,\n",
        "            'verbose': -1,\n",
        "        }\n",
        "\n",
        "    results = []\n",
        "    for set_name, features in feature_sets.items():\n",
        "        # Initialize and train the model\n",
        "        model = lgbm.LGBMRegressor(**model_params)\n",
        "        model.fit(train_data[features], train_data[test_date])\n",
        "\n",
        "        # Make predictions and evaluate the model\n",
        "        predictions = model.predict(test_data[features])\n",
        "        eval_results = evaluate_model(test_data[test_date], predictions)\n",
        "        eval_results['Feature Set'] = set_name  # Add feature set name for reference\n",
        "        results.append(eval_results)\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "mKVdcYxDrIzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training on 6 previous data points and embeddings\n",
        "import lightgbm as lgbm\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "\n",
        "TEST_DATE = '2024-08'\n",
        "TRAIN_START_DATE = '2024-02'\n",
        "TRAIN_END_DATE = '2024-07'\n",
        "\n",
        "train_dates = [x.strftime('%Y-%m') for x in pd.date_range(\n",
        "    start=TRAIN_START_DATE, end=TRAIN_END_DATE, freq='MS')]\n",
        "\n",
        "# Join embeddings with ground truth data (unemployment rate) for modeling\n",
        "data = county_embeddings.join(df_labels[train_dates + [TEST_DATE]])\n",
        "\n",
        "train_data = data.sample(n=1000, random_state=42)\n",
        "test_data = data.drop(train_data.index)\n",
        "print(f\"Training dates: {train_dates}\")\n",
        "print(f\"Test date: {TEST_DATE}\")\n",
        "print(f\"# Training counties: {train_data.shape[0]}\")\n",
        "print(f\"# Test counties: {test_data.shape[0]}\")\n",
        "\n",
        "# Define feature sets for different model configurations\n",
        "# 1. Using only past unemployment data\n",
        "# 2. Using only embeddings data\n",
        "# 3. Combining embeddings and past unemployment data to see additive improvements\n",
        "FEATURE_SETS = {\n",
        "    'Past Unemployment': train_dates,\n",
        "    'Embeddings Only': embedding_features,\n",
        "    'Embeddings + Past Unemployment': embedding_features + train_dates,\n",
        "}\n",
        "\n",
        "MODEL_PARAMS = {\n",
        "    'min_child_samples': 10,\n",
        "    'num_leaves': 23,\n",
        "    'max_bin': 100,\n",
        "    'n_estimators': 100,\n",
        "    'learning_rate': 0.1,\n",
        "    'force_col_wise': True,\n",
        "    'verbose': -1,\n",
        "}\n",
        "\n",
        "# Run training and evaluation for each feature set and display results\n",
        "evaluation_results = train_and_evaluate(\n",
        "    train_data=train_data,\n",
        "    test_data=test_data,\n",
        "    feature_sets=FEATURE_SETS,\n",
        "    test_date=TEST_DATE,\n",
        "    model_params=MODEL_PARAMS\n",
        ")\n",
        "\n",
        "print(\"Model Performance Results:\")\n",
        "evaluation_results.round(3)"
      ],
      "metadata": {
        "id": "sKoEkfu7MI3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that PDFM embeddings improve nowcasting accuracy when used in conjunction with past data."
      ],
      "metadata": {
        "id": "Sl835nbCGZg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title The improvements are bigger if there are fewer historical data points.\n",
        "# Define new training configuration for limited historical data\n",
        "MINHIST_TEST_DATE = '2024-08'\n",
        "MINHIST_TRAIN_START_DATE = '2024-07'\n",
        "MINHIST_TRAIN_END_DATE = '2024-07'\n",
        "\n",
        "minhist_train_dates = [x.strftime('%Y-%m') for x in pd.date_range(\n",
        "    start=MINHIST_TRAIN_START_DATE, end=MINHIST_TRAIN_END_DATE, freq='MS')]\n",
        "\n",
        "minhist_data = embeddings.join(df_labels[minhist_train_dates + [MINHIST_TEST_DATE]])\n",
        "\n",
        "minhist_train_data = minhist_data.sample(n=1000, random_state=42)\n",
        "minhist_test_data = minhist_data.drop(minhist_train_data.index)\n",
        "print(f\"Training dates with minimized history: {minhist_train_dates}\")\n",
        "print(f\"Test date: {MINHIST_TEST_DATE}\")\n",
        "print(f\"# Training counties: {minhist_train_data.shape[0]}\")\n",
        "print(f\"# Test counties: {minhist_test_data.shape[0]}\")\n",
        "\n",
        "MINHIST_FEATURE_SETS = {\n",
        "    'Past Unemployment (MinHist)': minhist_train_dates,\n",
        "    'Embeddings Only': embedding_features,\n",
        "    'Embeddings + Past Unemployment (MinHist)': embedding_features + minhist_train_dates,\n",
        "}\n",
        "\n",
        "minhist_results = train_and_evaluate(\n",
        "    train_data=minhist_train_data,\n",
        "    test_data=minhist_test_data,\n",
        "    feature_sets=MINHIST_FEATURE_SETS,\n",
        "    test_date=MINHIST_TEST_DATE,\n",
        "    model_params=MODEL_PARAMS  # Reuse parameters from previous model configuration\n",
        ")\n",
        "\n",
        "print(\"Performance with Minimized Historical Data Points:\")\n",
        "minhist_results.round(3)"
      ],
      "metadata": {
        "id": "YdlhK7KXe8YW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}